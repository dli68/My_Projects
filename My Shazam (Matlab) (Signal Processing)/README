
In this project I have coded a Shazam-like program to identify a short clip of music using a database of music. The basic procedure is:
1. Construct a database of features for each full-length song;2. When a clip (hopefully part of one of the songs in the database) is to be identified, calculate the corresponding features of the clip;3. Search the database for a match with the features of the clip.
Like Shazam, the features for each song (and clip) will be pairs of proximate peaks in the spectrogram of the song or clip. I start by finding the peaks in the (log) spectrogram; plotting the locations of these peaks gives a constellation map. Each peak has a time-frequency location (t,f) and a magnitude A. I then form pairs of peaks that are within a pre-specified time and frequency distance of each other and record the details of these pairs in the database. For example, if I obtained a pair (f1,t1) and (f2,t2), I might record (f1, f2, t1, t2 − t1, A1, A2, SONGID). I don’t want to record all possible pairs of peaks; there are far too many. Instead of recording (f1, f2, t1, t2−t1, A1, A2, SONGID), I will discard the amplitudes and just record (f1, f2, t1, t2 − t1, SONGID) since the amplitude of a peak may not be robust to gain changes across frequency.